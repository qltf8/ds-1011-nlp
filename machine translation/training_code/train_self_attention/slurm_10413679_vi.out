sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543342831_9840717/predict.txt | sacrebleu ../eval/1543342831_9840717/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 13.2 47.3/20.3/10.1/5.1 (BP = 0.883 ratio = 0.889 hyp_len = 25156 ref_len = 28283)\n')
epoch:  0  the blue score on validation dataset is :  13.2
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543344630_4649136/predict.txt | sacrebleu ../eval/1543344630_4649136/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 16.2 52.3/23.9/12.8/7.2 (BP = 0.876 ratio = 0.883 hyp_len = 24986 ref_len = 28283)\n')
epoch:  1  the blue score on validation dataset is :  16.2
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543346433_8660018/predict.txt | sacrebleu ../eval/1543346433_8660018/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 17.1 52.0/24.1/13.0/7.4 (BP = 0.921 ratio = 0.924 hyp_len = 26132 ref_len = 28283)\n')
epoch:  2  the blue score on validation dataset is :  17.1
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543348239_0983038/predict.txt | sacrebleu ../eval/1543348239_0983038/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 17.6 51.7/24.2/13.3/7.7 (BP = 0.928 ratio = 0.931 hyp_len = 26321 ref_len = 28283)\n')
epoch:  3  the blue score on validation dataset is :  17.6
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543350032_0011942/predict.txt | sacrebleu ../eval/1543350032_0011942/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 18.3 51.7/24.2/13.2/7.6 (BP = 0.969 ratio = 0.969 hyp_len = 27407 ref_len = 28283)\n')
epoch:  4  the blue score on validation dataset is :  18.3
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543351952_839353/predict.txt | sacrebleu ../eval/1543351952_839353/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 17.7 52.2/24.5/13.4/7.9 (BP = 0.924 ratio = 0.927 hyp_len = 26222 ref_len = 28283)\n')
epoch:  5  the blue score on validation dataset is :  17.7
sacreBLEU: That's 100 lines that end in a tokenized period ('.')
sacreBLEU: It looks like you forgot to detokenize your test data, which may hurt your score.
sacreBLEU: If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.
CompletedProcess(args='cat ../eval/1543354053_6694272/predict.txt | sacrebleu ../eval/1543354053_6694272/target_file_name.txt', returncode=0, stdout=b'BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.2.12 = 17.9 52.4/24.2/13.3/7.9 (BP = 0.938 ratio = 0.940 hyp_len = 26589 ref_len = 28283)\n')
epoch:  6  the blue score on validation dataset is :  17.9
Traceback (most recent call last):
  File "./train_better.py", line 501, in <module>
    run_epoch(data_iter=train_vi_en_iter, model=model, loss_compute=SimpleLossCompute(model.generator, criterion,), optimizer = optimizer)
  File "./train_better.py", line 455, in run_epoch
    processed_loss += loss_compute(out, target_true_word_index)
  File "./train_better.py", line 283, in __call__
    y.contiguous().view(-1))
  File "/home/ql819/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "./train_better.py", line 271, in forward
    return self.criterion(x, Variable(true_dist, requires_grad=False))
  File "/home/ql819/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/ql819/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 358, in forward
    return F.kl_div(input, target, reduction=self.reduction)
  File "/home/ql819/pytorch-gpu/py3.6.3/lib/python3.6/site-packages/torch/nn/functional.py", line 1503, in kl_div
    return torch._C._nn.kl_div(input, target, reduction)
RuntimeError: std::bad_alloc: temporary_buffer::allocate: get_temporary_buffer failed
